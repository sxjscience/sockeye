[train_data]
class=dataset.load_dataset_from_files
s_source="../../data/lv-en/train.tok.bpe.lv"
s_target="../../data/lv-en/train.tok.bpe.en"

[val_data]
class=dataset.load_dataset_from_files
s_source="../../data/lv-en/dev.bpe.lv"
s_target="../../data/lv-en/dev.bpe.en"

[shared_vocabulary]
class=vocabulary.from_bpe
path="../../data/lv-en/bpe.model"

[encoder]
class=encoders.recurrent.SentenceEncoder
name="sentence_encoder"
rnn_size=1000
max_input_len=50
embedding_size=500
dropout_keep_prob=0.7
rnn_cell="LSTM"
data_id="source"
vocabulary=<shared_vocabulary>

[decoder]
class=decoders.decoder.Decoder
name="decoder"
encoders=[<encoder>]
rnn_size=1000
embedding_size=500
dropout_keep_prob=0.7
rnn_cell="LSTM"
attentions=[<attention>]
data_id="target"
vocabulary=<shared_vocabulary>
max_output_len=50

[attention]
class=attention.Attention
name="attention_sentence_encoder"
encoder=<encoder>

[trainer]
class=trainers.cross_entropy_trainer.CrossEntropyTrainer
decoders=[<decoder>]
l2_weight=0
clip_norm=1.0
optimizer=<adam>

[adam]
class=config.utils.adam_optimizer
learning_rate=1.0e-4

[bs_decoder]
 class=decoders.beam_search_decoder.BeamSearchDecoder
 name="beam_search_decoder"
 parent_decoder=<decoder>
 length_normalization=0.6
 max_steps=60
 beam_size=5
 
[bs_runner]
 class=runners.beamsearch_runner.beam_search_runner_range
 output_series="target_beam"
 decoder=<bs_decoder>
 max_rank=5

[runner]
class=runners.runner.GreedyRunner
decoder=<decoder>
output_series="target"

[bleu]
class=evaluators.bleu.BLEUEvaluator
name="BLEU-4"

[tf_manager]
class=tf_manager.TensorFlowManager
num_threads=4
num_sessions=1
minimize_metric=False
save_n_best=3
report_gpu_memory_consumption=True

[main]
name="Groundhog"
tf_manager=<tf_manager>
output="groundhog"
overwrite_output_dir=True
runners=<bs_runner>
trainer=<trainer>
train_dataset=<train_data>
val_dataset=<val_data>
evaluation=[("target", "target", <bleu>)]
batch_size=80
runners_batch_size=1
epochs=20
validation_period=5000
logging_period=240
